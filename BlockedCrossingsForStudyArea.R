library(tidyverse)
library(httr)
library(sf)
library(tmap)
library(tigris)
library(raster)
tmap_mode("view")

#proj <- 26916
proj <- 4326

basemap <- tm_basemap(c("CartoDB.Positron", "OpenStreetMap.Mapnik", "Esri.WorldImagery")) + tm_tiles("OpenRailwayMap", alpha = 0.5)

# Download FRA Data for Blocked Crossing Reports --------------------------

# The API link below may need to be updated. To do that, go to: https://www.fra.dot.gov/blockedcrossings/incidents
# Press CTRL + SHIFT + I to open devtools. Go to the Network tab, make sure Fetch/XHR is clicked and refresh the page
# The Request URL that shows up is what you could use for the URL below. 
dataRaw <- 
  GET("https://www.fra.dot.gov/blockedcrossings/api/incidents?page=1&pageSize=500000") %>% 
  content()
blockedCrossings <- dataRaw$items %>% bind_rows() %>% rename(CrossingID = crossingID)

# Import Grade Crossing Inventory Data ------------------------------------

# Read in all Current US crossing data
# Note that this file is too large to be stored on github. 
# Download "All States" file from: https://safetydata.fra.dot.gov/OfficeofSafety/publicsite/DownloadCrossingInventoryData.aspx 

xings <- 
#  read_csv("C:/Users/frryan/Desktop/_Working Files/_R/FRA/CurrentInventory/PublishedCrossingData-04-30-2022.csv", #Chris
  read_csv("C:/Users/sferzli/Documents/Projects/US/MACOG/Grade Crossing Analysis/Data/GCIS_Published_Crossing_Data/PublishedCrossingData-05-31-2022.csv", #Steph
        col_types = cols(
             MilePost = col_double())) %>%
  filter(
    !is.na(Latitude), #filter xings without lat/long
    PosXing == 1, #filter only at-grade xings
    ReasonID != 16 #filter xings that have been closed
  ) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) 

# Import FRA Accident/Incident Records ------------------------------------

# The Accident data is small enough that it can be stored on GitHub

# Read in all Accident/Incident data
gcisAccHist <- map_dfr(
  c("Acc2016", "Acc2017", "Acc2018", "Acc2019", "Acc2020"),
  ~read_csv(paste0("Data/", ., ".csv"), 
            col_types = cols(.default = "c")) #default to character type to avoid conflicting autogenerated types
)


# Next step is to filter to the study area
MACOGSF <- read_sf("C:/Users/sferzli/Documents/Projects/US/MACOG/Grade Crossing Analysis/Data/Indiana Counties/d97376b1-781d-4aad-bacc-011171010eee2020413-1-1wbeqv7.muvgf.shp") %>% 
  filter(COUNTYNAME == "ELKHART" | COUNTYNAME == "KOSCIUSKO" | COUNTYNAME == "MARSHALL" | COUNTYNAME == "ST. JOSEPH") %>%
  st_transform(proj)


